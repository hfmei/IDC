data:
    dataset: "CIFAR10"
    category: "cifar10"
    image_size: 32
    num_channels: 3
    random_flip: True
    centered: True
    uniform_dequantization: False


idc:
    runner: "BBDMRunner"
    training:
        n_epochs: 400
        n_steps: 4000000
        save_interval: 5
        sample_interval: 5
        validation_interval: 5
        accumulate_grad_batches: 2

    model:
        model_name: "BrownianBridge" # part of result path
        model_type: "BBDM" # specify a module
        latent_before_quant_conv: False
        normalize_latent: False
        only_load_latent_mean_std: False
        num_classes: 10
        # model_load_path:  # model checkpoint path
        # optim_sche_load_path:  # optimizer scheduler checkpoint path

        EMA:
            use_ema: True
            ema_decay: 0.995
            update_ema_interval: 8 # step
            start_ema_step: 30000

        CondStageParams:
            n_stages: 2
            in_channels: 3
            out_channels: 3

        BB:
            optimizer:
                weight_decay: 0.000
                optimizer: 'Adam'
                lr: 1.e-4
                beta1: 0.9

            lr_scheduler:
                factor: 0.5
                patience: 3000
                threshold: 0.0001
                cooldown: 3000
                min_lr: 5.e-7

            params:
                mt_type: 'linear' # options {'linear', 'sin'}
                objective: 'grad' # options {'grad', 'noise', 'ysubx'}
                loss_type: 'l1' # options {'l1', 'l2'}

                skip_sample: True
                sample_type: 'linear' # options {"linear", "sin"}
                sample_step: 4

                num_timesteps: 4 # timesteps
                eta: 1.0 # DDIM reverse process eta
                max_var: 1.0 # maximum variance

                UNetParams:
                    image_size: 32
                    in_channels: 3
                    model_channels: 64
                    out_channels: 3
                    num_res_blocks: 1
                    attention_resolutions: !!python/tuple
                        - 32
                        - 16
                        - 8
                    channel_mult: !!python/tuple
                        - 1
                        - 4
                    conv_resample: True
                    dims: 2
                    num_heads: 8
                    num_head_channels: 32
                    use_scale_shift_norm: True
                    resblock_updown: True
                    use_spatial_transformer: False
                    context_dim:
                    condition_key: "nocond" # options {"SpatialRescaler", "first_stage", "nocond"}

training:
    sde: 'vpsde'
    continuous: True
    reduce_mean: True
    n_iters: 950001

optim:
    weight_decay: 0
    optimizer: 'Adam'
    lr: 0.0002  # 2e-4
    beta1: 0.9
    eps: 0.00000001  # 1e-8
    warmup: 5000
    grad_clip: 1.

sampling:
    n_steps_each: 1
    noise_removal: True
    probability_flow: False
    snr: 0.16
    method: 'pc'
    predictor: 'euler_maruyama'
    corrector: 'none'